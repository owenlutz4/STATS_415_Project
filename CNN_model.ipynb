{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59914953-7b34-417e-ae65-5212d0762959",
   "metadata": {},
   "outputs": [],
   "source": [
    "from platform import python_version\n",
    "\n",
    "print(python_version())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "682b6733-093d-4ec1-8f16-c2e33fdd50c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Dropout, Input, BatchNormalization\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "434f8dcf-645b-464e-9bbe-bf861c449e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef2b151b-a010-4ac6-ae2a-a741d51d8021",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in training data\n",
    "X_train = pd.read_csv(\"UCI_data/train/X_train.txt\", delim_whitespace=True, header=None)\n",
    "\n",
    "y_train = pd.read_csv(\"UCI_data/train/y_train.txt\", header=None)\n",
    "\n",
    "subject_train = pd.read_csv(\"UCI_data/train/subject_train.txt\", header=None)\n",
    "\n",
    "print(f\"X_train shape: {X_train.shape}\")\n",
    "print(f\"y_train shape: {y_train.shape}\")\n",
    "print(f\"subject_train shape: {subject_train.shape}\" ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20fdf914-b014-4931-8e37-6d2948e2f995",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in testing data\n",
    "X_test = pd.read_csv(\"UCI_data/test/X_test.txt\", delim_whitespace=True, header=None)\n",
    "\n",
    "y_test = pd.read_csv(\"UCI_data/test/y_test.txt\", header=None)\n",
    "\n",
    "subject_test = pd.read_csv(\"UCI_data/test/subject_test.txt\", header=None)\n",
    "\n",
    "print(f\"X_test shape: {X_test.shape}\")\n",
    "print(f\"y_test shape: {y_test.shape}\")\n",
    "print(f\"subject_test shape: {subject_test.shape}\" ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a75eb683-cf55-4da2-9376-6f0db19eed4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize all data together\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.fit_transform(X_test)\n",
    "\n",
    "# One-hot encode all labels together\n",
    "encoder = OneHotEncoder(sparse_output=False)\n",
    "y_train_encoded = encoder.fit_transform(y_train)\n",
    "y_test_encoded = encoder.fit_transform(y_test)\n",
    "\n",
    "y_train_encoded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54dcb319-0438-49e2-a4c1-2a5f273b0ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate dimensions\n",
    "n_timesteps = 11\n",
    "n_features = 51\n",
    "n_classes = y_train_encoded.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acc957b9-4057-49bd-8623-4f9cc0b94340",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape the data to include a channel dimension if needed\n",
    "X_train_reshaped = X_train_scaled.reshape(-1, n_timesteps, n_features)\n",
    "X_test_reshaped = X_test_scaled.reshape(-1, n_timesteps, n_features)\n",
    "\n",
    "X_train_reshaped.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8001731-0d0c-4d92-ab19-06c492a5e0ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating model\n",
    "def create_model(learning_rate, filters, dropout_rate, batch_size):\n",
    "    model = Sequential([\n",
    "        Input(shape=(n_timesteps, n_features)),\n",
    "        Conv1D(filters=filters,kernel_size=3,padding='same',activation='relu',kernel_regularizer=tf.keras.regularizers.l2(0.002)),\n",
    "        BatchNormalization(), \n",
    "        Dropout(dropout_rate),\n",
    "        MaxPooling1D(pool_size=2),\n",
    "        Conv1D(filters=filters, kernel_size=3,padding='same',activation='relu',kernel_regularizer=tf.keras.regularizers.l2(0.002)),\n",
    "        BatchNormalization(),\n",
    "        Dropout(dropout_rate),\n",
    "        MaxPooling1D(pool_size=2),\n",
    "        Flatten(),\n",
    "        Dense(64, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(dropout_rate),\n",
    "        Dense(32, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(dropout_rate),\n",
    "        Dense(6, activation='softmax')\n",
    "    ])\n",
    "    \n",
    "    optimizer = Adam(learning_rate=learning_rate)\n",
    "    model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Defining grid search\n",
    "def grid_search(X_train_reshaped, y_train_encoded, param_grid, n_splits=5):\n",
    "    best_score = 0\n",
    "    best_params = None\n",
    "    \n",
    "    # Convert one-hot encoded y back to class labels (for stratification)\n",
    "    y_train_classes = np.argmax(y_train_encoded, axis=1)\n",
    "    \n",
    "    # Use StratifiedKFold\n",
    "    skfold = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "    \n",
    "    for params in ParameterGrid(param_grid):\n",
    "        print(f\"\\nTrying params: {params}\")\n",
    "        fold_accuracies = []\n",
    "        \n",
    "        # Use y_train_classes for splitting\n",
    "        for train_index, val_index in skfold.split(X_train_reshaped, y_train_classes):\n",
    "            X_train_fold, X_val_fold = X_train_reshaped[train_index], X_train_reshaped[val_index]\n",
    "            y_train_fold, y_val_fold = y_train_encoded[train_index], y_train_encoded[val_index]\n",
    "            \n",
    "            model = create_model(\n",
    "                learning_rate=params['learning_rate'],\n",
    "                filters=params['filters'],\n",
    "                dropout_rate=params['dropout_rate'],\n",
    "                batch_size=params['batch_size']\n",
    "            )\n",
    "             \n",
    "            # Train with callbacks and validation data\n",
    "            model.fit(X_train_fold, y_train_fold, \n",
    "                     epochs=25, \n",
    "                     batch_size=params['batch_size'],\n",
    "                     validation_data=(X_val_fold, y_val_fold),\n",
    "                     verbose=0,)\n",
    "\n",
    "\n",
    "            score = model.evaluate(X_val_fold, y_val_fold, verbose=0)\n",
    "            fold_accuracies.append(score[1])\n",
    "            \n",
    "        avg_accuracy = np.mean(fold_accuracies)\n",
    "        print(f\"Average Validation Accuracy: {avg_accuracy:.4f}\")\n",
    "        \n",
    "        if avg_accuracy > best_score:\n",
    "            best_score = avg_accuracy\n",
    "            best_params = params\n",
    "            \n",
    "    return best_params, best_score,\n",
    "\n",
    "param_grid = {\n",
    "    'learning_rate': [0.0001, 0.0005],\n",
    "    'filters': [32, 64],\n",
    "    'dropout_rate': [0.3, 0.35],\n",
    "    'batch_size': [64, 128],\n",
    "}\n",
    "\n",
    "# Run grid search\n",
    "best_params, best_score = grid_search(X_train_reshaped, y_train_encoded, param_grid, n_splits=5)\n",
    "print(f\"\\nBest Parameters: {best_params}\")\n",
    "print(f\"Best Validation Accuracy: {best_score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19c10dc5-aa59-4f58-b41f-defff2f6b96b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model creation function with the optimal parameters\n",
    "def create_optimal_model():\n",
    "    return create_model(\n",
    "        learning_rate=best_params['learning_rate'],  \n",
    "        filters=best_params['filters'],           \n",
    "        dropout_rate=best_params['dropout_rate'],\n",
    "        batch_size=best_params['batch_size']\n",
    "    )\n",
    "\n",
    "# Train the model with the entire training set and capture the history\n",
    "model = create_optimal_model()\n",
    "history = model.fit(X_train_reshaped, y_train_encoded, epochs=20, batch_size=32, verbose=1, validation_split=0.2,\n",
    "                   callbacks = [tf.keras.callbacks.ModelCheckpoint(\n",
    "                       'best_model.weights.h5',\n",
    "                       monitor='val_loss',\n",
    "                       save_best_only=True,\n",
    "                       mode='min',\n",
    "                       save_weights_only=True\n",
    "                   )])\n",
    "\n",
    "# Define a function to plot the accuracy and loss\n",
    "def plot_accuracy_and_loss(history):\n",
    "    \n",
    "    # Plot training & validation accuracy values\n",
    "    plt.figure(figsize=(12, 5))\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(history.history['accuracy'])\n",
    "    plt.plot(history.history['val_accuracy'])\n",
    "    plt.title('Model Accuracy')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Training', 'Validation'], loc='upper left')\n",
    "\n",
    "    # Plot training & validation loss values\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('Model Loss')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Training', 'Validation'], loc='upper left')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Call the plotting function\n",
    "plot_accuracy_and_loss(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0326b49a-eac4-42e0-9670-5db6fa6368fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from mlxtend.plotting import plot_confusion_matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Modifing y_pred and y_test\n",
    "y_pred = model.predict(X_test_reshaped)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "y_test_classes = np.argmax(y_test_encoded, axis=1)\n",
    "\n",
    "\n",
    "# Plotting confusion matrix\n",
    "def plot_confusion_matrix(y_true, y_pred, classes, filename):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    plt.figure(figsize=(12,10))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=classes, yticklabels=classes)\n",
    "    plt.title('Confusion Matrix of Human Activities') \n",
    "    plt.ylabel('True Activity')\n",
    "    plt.xlabel('Predicted Activity')\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.yticks(rotation=45, ha='right')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(filename, bbox_inches='tight', dpi=300)\n",
    "    plt.close()\n",
    "\n",
    "activity_labels = ['WALKING', 'WALKING_UPSTAIRS', 'WALKING_DOWNSTAIRS', 'SITTING', 'STANDING', 'LAYING']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23d2835d-d9e0-4c9b-9d84-d2d34f206743",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_accuracy = model.evaluate(X_test_reshaped, y_test_encoded)\n",
    "print(f\"Test Accuracy: {test_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea2a775b-46a0-45c6-8fa3-4b48032ef248",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import psutil\n",
    "\n",
    "def measure_inference_performance(model, X_test, n_runs=100):\n",
    "    \"\"\"\n",
    "    Measure inference time and memory usage of the model.\n",
    "    Args:\n",
    "        model: Trained TensorFlow model\n",
    "        X_test: Test data\n",
    "        n_runs: Number of inference runs to average over\n",
    "    Returns:\n",
    "        dict: Performance metrics\n",
    "    \"\"\"\n",
    "    # Warm up the model\n",
    "    for _ in range(5):\n",
    "        model.predict(X_test[:1])\n",
    "    \n",
    "    # Measure inference time\n",
    "    latencies = []\n",
    "    memory_usage = []\n",
    "    \n",
    "    for _ in range(n_runs):\n",
    "        # Single sample inference (real-time scenario)\n",
    "        start_time = time.time()\n",
    "        model.predict(X_test[:1])\n",
    "        latencies.append((time.time() - start_time) * 1000)\n",
    "        \n",
    "        # Memory usage\n",
    "        process = psutil.Process()\n",
    "        memory_usage.append(process.memory_info().rss / 1024 / 1024)  # Convert to MB\n",
    "    \n",
    "    metrics = {\n",
    "        'avg_inference_time_ms': np.mean(latencies),\n",
    "        'std_inference_time_ms': np.std(latencies),\n",
    "        'max_inference_time_ms': np.max(latencies),\n",
    "        'p95_inference_time_ms': np.percentile(latencies, 95),\n",
    "        'avg_memory_usage_mb': np.mean(memory_usage),\n",
    "        'peak_memory_usage_mb': np.max(memory_usage)\n",
    "    }\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "# Add to model evaluation section:\n",
    "print(\"\\nMeasuring real-time performance metrics...\")\n",
    "performance_metrics = measure_inference_performance(model, X_test_reshaped)\n",
    "\n",
    "print(\"\\nReal-time Performance Metrics:\")\n",
    "print(f\"Average Inference Time: {performance_metrics['avg_inference_time_ms']:.2f} ms\")\n",
    "print(f\"95th Percentile Inference Time: {performance_metrics['p95_inference_time_ms']:.2f} ms\")\n",
    "print(f\"Maximum Inference Time: {performance_metrics['max_inference_time_ms']:.2f} ms\")\n",
    "print(f\"Average Memory Usage: {performance_metrics['avg_memory_usage_mb']:.2f} MB\")\n",
    "print(f\"Peak Memory Usage: {performance_metrics['peak_memory_usage_mb']:.2f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc949c85-cc73-4ee4-8bd4-a456feda650d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "from datetime import datetime\n",
    "\n",
    "def create_output_directory(base_dir=\"outputs\"):\n",
    "    \"\"\"Create timestamped output directory\"\"\"\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    output_dir = os.path.join(base_dir, f\"run_{timestamp}\")\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    return output_dir\n",
    "\n",
    "def save_model_artifacts(model, history, X_test_reshaped, y_test, output_dir):\n",
    "    \"\"\"Save model, weights, and all related artifacts\"\"\"\n",
    "    \n",
    "    # Save model architecture and weights\n",
    "    model_path = os.path.join(output_dir, \"final_model.h5\")\n",
    "    weights_path = os.path.join(output_dir, \"best_model.weights.h5\")  # Note this change\n",
    "    model.save(model_path)\n",
    "    model.save_weights(weights_path)\n",
    "    \n",
    "    # Plot and save training history\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(history.history['accuracy'])\n",
    "    plt.plot(history.history['val_accuracy'])\n",
    "    plt.title('Model Accuracy')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('Model Loss')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(output_dir, 'training_history.png'), dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "    # Save confusion matrix\n",
    "    plot_confusion_matrix(y_test_classes, y_pred_classes, activity_labels, \n",
    "    os.path.join(output_dir, 'confusion_matrix.png'))\n",
    "\n",
    "    # Save metrics to inference results file\n",
    "    with open(os.path.join(output_dir, 'inference_results.txt'), 'w') as f:\n",
    "        f.write('Real-time Performance Metrics:\\n')\n",
    "        for metric, value in performance_metrics.items():\n",
    "            f.write(f\"{metric}: {value:.2f}\\n\")\n",
    "    \n",
    "    # Create a summary text file\n",
    "    with open(os.path.join(output_dir, 'summary.txt'), 'w') as f:\n",
    "        f.write(f\"Model Training Summary\\n\")\n",
    "        f.write(f\"Timestamp: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\")\n",
    "        f.write(f\"\\nFinal Training Accuracy: {history.history['accuracy'][-1]:.4f}\")\n",
    "        f.write(f\"\\nFinal Validation Accuracy: {history.history['val_accuracy'][-1]:.4f}\")\n",
    "        f.write(f\"\\nFinal Training Loss: {history.history['loss'][-1]:.4f}\")\n",
    "        f.write(f\"\\nFinal Validation Loss: {history.history['val_loss'][-1]:.4f}\")\n",
    "\n",
    "def save_grid_search_results(best_params, best_score, output_dir):\n",
    "    \"\"\"Save the best parameters and score from the grid search\"\"\"\n",
    "    summary_path = os.path.join(output_dir, \"grid_search_summary.txt\")\n",
    "    with open(summary_path, 'w') as f:\n",
    "        f.write(\"Grid Search Results Summary\\n\\n\")\n",
    "        f.write(f\"Best Score: {best_score:.4f}\\n\\n\")\n",
    "        f.write(\"Best Parameters:\\n\")\n",
    "        for param, value in best_params.items():\n",
    "            f.write(f\"{param}: {value}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31250fb0-9a55-4893-a1d8-71f4a4f526f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create output directory\n",
    "output_dir = create_output_directory()\n",
    "\n",
    "save_model_artifacts(model, history, X_test_reshaped, y_test, output_dir)\n",
    "\n",
    "save_grid_search_results(best_params, best_score, output_dir)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
