{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOUkk6H2oHs9qOGkEc3qys3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/owenlutz4/STATS_415_Project/blob/main/CNN-LSTM_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from datetime import datetime\n",
        "import os\n",
        "\n",
        "print(\"Loading data...\")\n",
        "\n",
        "try:\n",
        "    # Load training data\n",
        "    X_train = pd.read_csv(\"UCI_data/train/X_train.txt\", sep='\\s+', header=None)\n",
        "    y_train = pd.read_csv(\"UCI_data/train/y_train.txt\", header=None)\n",
        "    subject_train = pd.read_csv(\"UCI_data/train/subject_train.txt\", header=None)\n",
        "\n",
        "    # Load test data\n",
        "    X_test = pd.read_csv(\"UCI_data/test/X_test.txt\", sep='\\s+', header=None)\n",
        "    y_test = pd.read_csv(\"UCI_data/test/y_test.txt\", header=None)\n",
        "    subject_test = pd.read_csv(\"UCI_data/test/subject_test.txt\", header=None)\n",
        "\n",
        "    print(\"Initial data shapes:\")\n",
        "    print(f\"X_train shape: {X_train.shape}\")\n",
        "    print(f\"y_train shape: {y_train.shape}\")\n",
        "    print(f\"X_test shape: {X_test.shape}\")\n",
        "    print(f\"y_test shape: {y_test.shape}\")\n",
        "except Exception as e:\n",
        "    print(\"Failed to load data:\", str(e))\n",
        "    raise\n",
        "\n",
        "# Normalize the data\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# One-hot encode labels\n",
        "encoder = OneHotEncoder(sparse_output=False)\n",
        "y_train_encoded = encoder.fit_transform(y_train)\n",
        "y_test_encoded = encoder.transform(y_test)\n",
        "\n",
        "# Get labels for the stratification\n",
        "y_train_classes = np.argmax(y_train_encoded, axis=1)\n",
        "\n",
        "# Calculate dimensions\n",
        "n_timesteps = 11\n",
        "n_features = 51\n",
        "n_classes = y_train_encoded.shape[1]\n",
        "\n",
        "# Reshape data for CNN-LSTM\n",
        "X_train_reshaped = X_train_scaled.reshape(-1, n_timesteps, n_features)\n",
        "X_test_reshaped = X_test_scaled.reshape(-1, n_timesteps, n_features)\n",
        "\n",
        "def create_model(conv_filters, lstm_units, dropout_rate):\n",
        "    model = tf.keras.Sequential([\n",
        "        tf.keras.layers.Input(shape=(n_timesteps, n_features)),\n",
        "        tf.keras.layers.Conv1D(\n",
        "            filters=conv_filters,\n",
        "            kernel_size=5,\n",
        "            activation='relu',\n",
        "            kernel_regularizer=tf.keras.regularizers.l2(0.0005)\n",
        "        ),\n",
        "        tf.keras.layers.BatchNormalization(),\n",
        "        tf.keras.layers.Dropout(dropout_rate),\n",
        "        tf.keras.layers.MaxPooling1D(pool_size=2),\n",
        "        tf.keras.layers.LSTM(\n",
        "            lstm_units,\n",
        "            return_sequences=False,\n",
        "            kernel_regularizer=tf.keras.regularizers.l2(0.0005),\n",
        "            recurrent_regularizer=tf.keras.regularizers.l2(0.0005)\n",
        "        ),\n",
        "        tf.keras.layers.Dropout(dropout_rate),\n",
        "        tf.keras.layers.Dense(\n",
        "            32,\n",
        "            activation='relu',\n",
        "            kernel_regularizer=tf.keras.regularizers.l2(0.0005)\n",
        "        ),\n",
        "        tf.keras.layers.BatchNormalization(),\n",
        "        tf.keras.layers.Dense(\n",
        "          n_classes,\n",
        "          activation='softmax',\n",
        "          kernel_regularizer=tf.keras.regularizers.l2(0.0005)\n",
        "        )\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "# Define parameter grid\n",
        "param_grid = {\n",
        "    'conv_filters': [32, 64],\n",
        "    'lstm_units': [32, 64],\n",
        "    'dropout_rate': [0.25, 0.35],\n",
        "    'learning_rate': [0.0001, 0.0005],\n",
        "    'batch_size': [64, 128]\n",
        "}\n",
        "\n",
        "def grid_search_cv():\n",
        "    best_accuracy = 0\n",
        "    best_params = {}\n",
        "    results = []\n",
        "\n",
        "    total_combinations = (len(param_grid['conv_filters']) *\n",
        "                        len(param_grid['lstm_units']) *\n",
        "                        len(param_grid['dropout_rate']) *\n",
        "                        len(param_grid['learning_rate']) *\n",
        "                        len(param_grid['batch_size']))\n",
        "\n",
        "    print(f\"Starting grid search with {total_combinations} combinations...\")\n",
        "    combination_count = 0\n",
        "\n",
        "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "    try:\n",
        "        for conv_filters in param_grid['conv_filters']:\n",
        "            for lstm_units in param_grid['lstm_units']:\n",
        "                for dropout_rate in param_grid['dropout_rate']:\n",
        "                    for learning_rate in param_grid['learning_rate']:\n",
        "                        for batch_size in param_grid['batch_size']:\n",
        "                            combination_count += 1\n",
        "                            print(f\"\\nTrying combination {combination_count}/{total_combinations}\")\n",
        "                            print(f\"Parameters: conv_filters={conv_filters}, lstm_units={lstm_units}, \"\n",
        "                                  f\"dropout_rate={dropout_rate}, lr={learning_rate}, batch_size={batch_size}\")\n",
        "\n",
        "                            cv_scores = []\n",
        "\n",
        "                            for fold, (train_idx, val_idx) in enumerate(skf.split(X_train_reshaped, y_train_classes)):\n",
        "                                print(f\"Fold {fold+1}/5\")\n",
        "\n",
        "                                X_fold_train = X_train_reshaped[train_idx]\n",
        "                                y_fold_train = y_train_encoded[train_idx]\n",
        "                                X_fold_val = X_train_reshaped[val_idx]\n",
        "                                y_fold_val = y_train_encoded[val_idx]\n",
        "\n",
        "                                try:\n",
        "                                    model = create_model(conv_filters, lstm_units, dropout_rate)\n",
        "                                    model.compile(\n",
        "                                        optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n",
        "                                        loss='categorical_crossentropy',\n",
        "                                        metrics=['accuracy']\n",
        "                                    )\n",
        "\n",
        "                                    model.fit(\n",
        "                                        X_fold_train,\n",
        "                                        y_fold_train,\n",
        "                                        epochs=50,\n",
        "                                        batch_size=batch_size,\n",
        "                                        validation_data=(X_fold_val, y_fold_val),\n",
        "                                        callbacks=[\n",
        "                                            tf.keras.callbacks.EarlyStopping(\n",
        "                                                monitor='val_loss',\n",
        "                                                patience=3,\n",
        "                                                restore_best_weights=True,\n",
        "                                                min_delta=0.005\n",
        "                                            )\n",
        "                                        ],\n",
        "                                        verbose=0\n",
        "                                    )\n",
        "\n",
        "                                    _, fold_accuracy = model.evaluate(X_fold_val, y_fold_val, verbose=0)\n",
        "                                    cv_scores.append(fold_accuracy)\n",
        "\n",
        "                                except tf.errors.ResourceExhaustedError:\n",
        "                                    print(f\"Skipping fold {fold+1} due to memory error\")\n",
        "                                    continue\n",
        "                                finally:\n",
        "                                    tf.keras.backend.clear_session()\n",
        "\n",
        "                            if cv_scores:\n",
        "                                mean_cv_accuracy = np.mean(cv_scores)\n",
        "                                std_cv_accuracy = np.std(cv_scores)\n",
        "                                print(f\"\\nMean CV accuracy: {mean_cv_accuracy:.4f} (+/- {std_cv_accuracy:.4f})\")\n",
        "\n",
        "                                results.append({\n",
        "                                    'conv_filters': conv_filters,\n",
        "                                    'lstm_units': lstm_units,\n",
        "                                    'dropout_rate': dropout_rate,\n",
        "                                    'learning_rate': learning_rate,\n",
        "                                    'batch_size': batch_size,\n",
        "                                    'mean_cv_accuracy': mean_cv_accuracy,\n",
        "                                    'std_cv_accuracy': std_cv_accuracy\n",
        "                                })\n",
        "\n",
        "                                if mean_cv_accuracy > best_accuracy:\n",
        "                                    best_accuracy = mean_cv_accuracy\n",
        "                                    best_params = {\n",
        "                                        'conv_filters': conv_filters,\n",
        "                                        'lstm_units': lstm_units,\n",
        "                                        'dropout_rate': dropout_rate,\n",
        "                                        'learning_rate': learning_rate,\n",
        "                                        'batch_size': batch_size\n",
        "                                    }\n",
        "                                    print(f\"\\nNew best accuracy: {best_accuracy:.4f}\")\n",
        "\n",
        "    except KeyboardInterrupt:\n",
        "        print(\"\\nGrid search interrupted by user\")\n",
        "        if best_params:\n",
        "            return best_params, best_accuracy, results\n",
        "        raise\n",
        "\n",
        "    return best_params, best_accuracy, results\n",
        "\n",
        "print(\"Starting grid search with 5-fold cross validation...\")\n",
        "best_params, best_accuracy, all_results = grid_search_cv()\n",
        "\n",
        "print(\"\\nGrid search complete!\")\n",
        "print(f\"Best parameters found:\")\n",
        "print(f\"- Conv filters: {best_params['conv_filters']}\")\n",
        "print(f\"- LSTM units: {best_params['lstm_units']}\")\n",
        "print(f\"- Dropout rate: {best_params['dropout_rate']}\")\n",
        "print(f\"- Learning rate: {best_params['learning_rate']}\")\n",
        "print(f\"- Batch size: {best_params['batch_size']}\")\n",
        "print(f\"Best CV accuracy: {best_accuracy:.4f}\")\n",
        "\n",
        "# Train final model\n",
        "print(\"\\nTraining final model with best parameters...\")\n",
        "final_model = create_model(\n",
        "    best_params['conv_filters'],\n",
        "    best_params['lstm_units'],\n",
        "    best_params['dropout_rate']\n",
        ")\n",
        "\n",
        "final_model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=best_params['learning_rate']),\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "base_dir = 'model_outputs'\n",
        "output_dir = f'{base_dir}_{timestamp}'\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "final_history = final_model.fit(\n",
        "    X_train_reshaped,\n",
        "    y_train_encoded,\n",
        "    epochs=50,\n",
        "    batch_size=best_params['batch_size'],\n",
        "    validation_split=0.2,\n",
        "    callbacks=[\n",
        "        tf.keras.callbacks.EarlyStopping(\n",
        "            monitor='val_loss',\n",
        "            patience=3,\n",
        "            restore_best_weights=True,\n",
        "            min_delta=0.005\n",
        "        ),\n",
        "        tf.keras.callbacks.ModelCheckpoint(\n",
        "            'best_model.weights.h5',\n",
        "            monitor='val_loss',\n",
        "            save_best_only=True,\n",
        "            mode='min',\n",
        "            save_weights_only=True\n",
        "        )\n",
        "    ],\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "print(\"\\nEvaluating final model...\")\n",
        "test_loss, test_accuracy = final_model.evaluate(X_test_reshaped, y_test_encoded)\n",
        "print(f\"Final Test Accuracy: {test_accuracy:.4f}\")\n",
        "\n",
        "y_pred = final_model.predict(X_test_reshaped)\n",
        "y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "y_test_classes = np.argmax(y_test_encoded, axis=1)\n",
        "\n",
        "activity_labels = [\n",
        "    'WALKING',\n",
        "    'WALKING_UPSTAIRS',\n",
        "    'WALKING_DOWNSTAIRS',\n",
        "    'SITTING',\n",
        "    'STANDING',\n",
        "    'LAYING'\n",
        "]\n",
        "\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test_classes, y_pred_classes, target_names=activity_labels))\n",
        "\n",
        "def plot_confusion_matrix(y_true, y_pred, classes, filename):\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    plt.figure(figsize=(12, 10))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "                xticklabels=classes, yticklabels=classes)\n",
        "    plt.title('Confusion Matrix of Human Activities')\n",
        "    plt.ylabel('True Activity')\n",
        "    plt.xlabel('Predicted Activity')\n",
        "    plt.xticks(rotation=45, ha='right')\n",
        "    plt.yticks(rotation=45, ha='right')\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(filename, bbox_inches='tight', dpi=300)\n",
        "    plt.close()\n",
        "\n",
        "plot_confusion_matrix(\n",
        "    y_test_classes,\n",
        "    y_pred_classes,\n",
        "    activity_labels,\n",
        "    os.path.join(output_dir, 'confusion_matrix.png')\n",
        ")\n",
        "\n",
        "# Accuracy History Plot\n",
        "\n",
        "plt.figure(figsize=(12, 4))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(final_history.history['accuracy'], label='Training')\n",
        "plt.plot(final_history.history['val_accuracy'], label='Validation')\n",
        "plt.title('Model Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "# Loss History Plot\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(final_history.history['loss'], label='Training')\n",
        "plt.plot(final_history.history['val_loss'], label='Validation')\n",
        "plt.title('Model Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig(os.path.join(output_dir, 'training_history.png'))\n",
        "plt.close()\n",
        "\n",
        "try:\n",
        "    model_path = os.path.join(output_dir, 'final_model.h5')\n",
        "    final_model.save(model_path)\n",
        "    print(f\"Model saved to: {model_path}\")\n",
        "except Exception as e:\n",
        "    print(f\"Error saving model: {str(e)}\")\n",
        "    try:\n",
        "        backup_path = os.path.join(output_dir, 'final_model_backup')\n",
        "        final_model.save(backup_path, save_format='tf')\n",
        "        print(f\"Model saved to backup location: {backup_path}\")\n",
        "    except Exception as e2:\n",
        "        print(f\"Failed to save backup model: {str(e2)}\")\n",
        "\n",
        "results_df = pd.DataFrame(all_results)\n",
        "results_df.to_csv(os.path.join(output_dir, 'grid_search_results.csv'), index=False)\n",
        "\n",
        "print(f\"\\nOutputs saved to: {output_dir}\")\n",
        "\n",
        "def cleanup():\n",
        "   tf.keras.backend.clear_session()\n",
        "   plt.close('all')\n",
        "   if os.path.exists('best_model.weights.h5'):\n",
        "       os.remove('best_model.weights.h5')\n",
        "\n",
        "import atexit\n",
        "atexit.register(cleanup)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "   try:\n",
        "       print(\"Starting training process...\")\n",
        "   except Exception as e:\n",
        "       print(f\"Error in main process: {str(e)}\")\n",
        "   finally:\n",
        "       cleanup()"
      ],
      "metadata": {
        "id": "QkbA2TGfHqVj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import psutil\n",
        "import numpy as np\n",
        "import os\n",
        "from datetime import datetime\n",
        "\n",
        "def measure_inference_performance(model, X_test, n_runs=100):\n",
        "    \"\"\"\n",
        "    Measure inference time and memory usage of the model.\n",
        "\n",
        "    Args:\n",
        "        model: Trained TensorFlow model\n",
        "        X_test: Test data\n",
        "        n_runs: Number of inference runs to average over\n",
        "\n",
        "    Returns:\n",
        "        dict: Performance metrics\n",
        "    \"\"\"\n",
        "    # Warm up the model\n",
        "    for _ in range(5):\n",
        "        model.predict(X_test[:1])\n",
        "\n",
        "    # Measure inference time\n",
        "    latencies = []\n",
        "    memory_usage = []\n",
        "\n",
        "    for _ in range(n_runs):\n",
        "        # Single sample inference (real-time scenario)\n",
        "        start_time = time.time()\n",
        "        model.predict(X_test[:1])\n",
        "        latencies.append((time.time() - start_time) * 1000)  # Convert to milliseconds\n",
        "\n",
        "        # Memory usage\n",
        "        process = psutil.Process()\n",
        "        memory_usage.append(process.memory_info().rss / 1024 / 1024)  # Convert to MB\n",
        "\n",
        "    metrics = {\n",
        "        'avg_inference_time_ms': np.mean(latencies),\n",
        "        'std_inference_time_ms': np.std(latencies),\n",
        "        'max_inference_time_ms': np.max(latencies),\n",
        "        'p95_inference_time_ms': np.percentile(latencies, 95),\n",
        "        'avg_memory_usage_mb': np.mean(memory_usage),\n",
        "        'peak_memory_usage_mb': np.max(memory_usage)\n",
        "    }\n",
        "\n",
        "    return metrics\n",
        "\n",
        "# Add to model evaluation section:\n",
        "print(\"\\nMeasuring real-time performance metrics...\")\n",
        "performance_metrics = measure_inference_performance(final_model, X_test_reshaped)\n",
        "\n",
        "print(\"\\nReal-time Performance Metrics:\")\n",
        "print(f\"Average Inference Time: {performance_metrics['avg_inference_time_ms']:.2f} ms\")\n",
        "print(f\"95th Percentile Inference Time: {performance_metrics['p95_inference_time_ms']:.2f} ms\")\n",
        "print(f\"Maximum Inference Time: {performance_metrics['max_inference_time_ms']:.2f} ms\")\n",
        "print(f\"Average Memory Usage: {performance_metrics['avg_memory_usage_mb']:.2f} MB\")\n",
        "print(f\"Peak Memory Usage: {performance_metrics['peak_memory_usage_mb']:.2f} MB\")\n",
        "\n",
        "# Create output directory if it doesn't exist\n",
        "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "base_dir = 'model_outputs'\n",
        "output_dir = f'{base_dir}_{timestamp}'\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "# Save metrics to inference results file\n",
        "with open(os.path.join(output_dir, 'inference_results.txt'), 'w') as f:\n",
        "    f.write('Real-time Performance Metrics:\\n')\n",
        "    for metric, value in performance_metrics.items():\n",
        "        f.write(f\"{metric}: {value:.2f}\\n\")"
      ],
      "metadata": {
        "id": "ouaDlmdHgirv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}